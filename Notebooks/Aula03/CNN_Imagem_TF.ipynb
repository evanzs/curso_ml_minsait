{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "#configurando para rodar em CPU\n",
    "tf.config.set_visible_devices([],'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prática\n",
    "1. Aquisição e pré-processamento dos dados\n",
    "2. Treinamento\n",
    "* Implementar arquitetura\n",
    "* Definir otimizadores, métricas e regularizadores\n",
    "3. Teste (avaliação de desempenho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Aquisição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANb0lEQVR4nO3df6gd9ZnH8c9ntVE0kSRK9GL91aioKCZrFMW6uJaUrCixYNcGWVxWuPmjShUhGyoYYVPQXeNKEAsparNLN6UQQ6WsNBLCuv5TEjWrMbFNNsT0JiHBDVrrP9H47B93Itfknjk3Z2bOnHuf9wsu55x5zsw8HPLJzDnz4+uIEICp7y/abgBAfxB2IAnCDiRB2IEkCDuQxOn9XJltfvoHGhYRHm96pS277UW2f297t+3lVZYFoFnu9Ti77dMk/UHSQkkjkrZIWhIRO0rmYcsONKyJLftNknZHxJ6IOCrpl5IWV1gegAZVCfuFkv445vVIMe1rbA/b3mp7a4V1Aaioyg904+0qnLSbHhFrJK2R2I0H2lRlyz4i6aIxr78p6UC1dgA0pUrYt0i6wvZltqdJ+oGkV+tpC0Ddet6Nj4gvbD8k6beSTpP0UkS8X1tnAGrV86G3nlbGd3agcY2cVANg8iDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIm+DtmMZlxzzTUda3fddVfpvMPDw6X1LVu2lNbfeeed0nqZ5557rrR+9OjRnpeNk7FlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGMV1Eli6dGlp/ZlnnulYmz59et3t1OaOO+4orW/evLlPnUwtnUZxrXRSje29kj6VdEzSFxGxoMryADSnjjPo/joiPqphOQAaxHd2IImqYQ9JG22/ZXvck6xtD9veantrxXUBqKDqbvytEXHA9hxJr9v+ICLeGPuGiFgjaY3ED3RAmypt2SPiQPF4WNIGSTfV0RSA+vUcdttn255x/Lmk70raXldjAOrV83F229/S6NZcGv068B8R8ZMu87Ab34PZs2eX1nfu3NmxNmfOnLrbqc3HH39cWr/vvvtK6xs3bqyxm6mj9uPsEbFH0vU9dwSgrzj0BiRB2IEkCDuQBGEHkiDsQBLcSnoSOHLkSGl9xYoVHWurVq0qnfess84qre/bt6+0fvHFF5fWy8ycObO0vmjRotI6h95ODVt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCW0lPcdu2bSutX399+YWL27eX36Lg2muvPdWWJmzu3Lml9T179jS27sms0yWubNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmuZ5/iVq5cWVp//PHHS+vz5s2rsZtTM23atNbWPRWxZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLiePbkLLrigtN7t3uzXXXddne18zfr160vr9957b2Prnsx6vp7d9ku2D9vePmbabNuv295VPM6qs1kA9ZvIbvzPJZ04NMdySZsi4gpJm4rXAAZY17BHxBuSThx/aLGktcXztZLuqbctAHXr9dz48yPioCRFxEHbczq90fawpOEe1wOgJo1fCBMRayStkfiBDmhTr4feDtkekqTi8XB9LQFoQq9hf1XSA8XzByT9up52ADSl62687XWSbpd0nu0RSSskPSXpV7YflLRP0vebbBK9u//++0vr3e4b3+R94bt58803W1v3VNQ17BGxpEPpOzX3AqBBnC4LJEHYgSQIO5AEYQeSIOxAElziOglcddVVpfUNGzZ0rF1++eWl855++uDeTZwhm3vDkM1AcoQdSIKwA0kQdiAJwg4kQdiBJAg7kMTgHmTFV66++urS+mWXXdaxNsjH0bt59NFHS+sPP/xwnzqZGtiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASk/cgbCJl16tL0rJlyzrWnn766dJ5zzzzzJ566oehoaG2W5hS2LIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIcZ58CVq9e3bG2a9eu0nlnzpxZad3drpd//vnnO9bOOeecSuvGqem6Zbf9ku3DtrePmfak7f22txV/dzbbJoCqJrIb/3NJi8aZ/q8RMa/4+8962wJQt65hj4g3JB3pQy8AGlTlB7qHbL9b7ObP6vQm28O2t9reWmFdACrqNew/lTRX0jxJByWt6vTGiFgTEQsiYkGP6wJQg57CHhGHIuJYRHwp6WeSbqq3LQB16ynstsdee/g9Sds7vRfAYOh6nN32Okm3SzrP9oikFZJutz1PUkjaK2lpcy2iitdee63R5dvjDgX+lbLx4Z944onSeefNm1dav+SSS0rrH374YWk9m65hj4gl40x+sYFeADSI02WBJAg7kARhB5Ig7EAShB1IgktcUcm0adNK690Or5X5/PPPS+vHjh3redkZsWUHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zo5KVq5c2diyX3yx/OLKkZGRxtY9FbFlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHBH9W5ndv5XV7Nxzz+1Ye/nll0vnXbduXaV6m4aGhkrrH3zwQWm9yrDMc+fOLa3v2bOn52VPZREx7v292bIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJczz5Bq1ev7li7++67S+e98sorS+sHDhwore/fv7+0vnv37o61G264oXTebr0tW7astF7lOPqqVatK690+F5yarlt22xfZ3mx7p+33bf+omD7b9uu2dxWPs5pvF0CvJrIb/4WkxyLiakk3S/qh7WskLZe0KSKukLSpeA1gQHUNe0QcjIi3i+efStop6UJJiyWtLd62VtI9DfUIoAan9J3d9qWS5kv6naTzI+KgNPofgu05HeYZljRcsU8AFU047LanS1ov6ZGI+JM97rn2J4mINZLWFMuYtBfCAJPdhA692f6GRoP+i4h4pZh8yPZQUR+SdLiZFgHUoeslrh7dhK+VdCQiHhkz/V8k/V9EPGV7uaTZEVF6nGYyb9lvvvnmjrVnn322dN5bbrml0rr37t1bWt+xY0fH2m233VY674wZM3pp6Svd/v2UXQJ74403ls772Wef9dRTdp0ucZ3Ibvytkv5O0nu2txXTfizpKUm/sv2gpH2Svl9DnwAa0jXsEfGmpE5f0L9TbzsAmsLpskAShB1IgrADSRB2IAnCDiTBraRr0O1SzbJLUCXphRdeqLOdvjpy5EhpvewW3GgGt5IGkiPsQBKEHUiCsANJEHYgCcIOJEHYgSS4lXQNHnvssdL6GWecUVqfPn16pfXPnz+/Y23JkiWVlv3JJ5+U1hcuXFhp+egftuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATXswNTDNezA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EASXcNu+yLbm23vtP2+7R8V05+0vd/2tuLvzubbBdCrrifV2B6SNBQRb9ueIektSfdI+ltJf46IZya8Mk6qARrX6aSaiYzPflDSweL5p7Z3Srqw3vYANO2UvrPbvlTSfEm/KyY9ZPtd2y/ZntVhnmHbW21vrdYqgComfG687emS/kvSTyLiFdvnS/pIUkj6J43u6v9Dl2WwGw80rNNu/ITCbvsbkn4j6bcR8ew49Usl/SYiru2yHMIONKznC2FsW9KLknaODXrxw91x35O0vWqTAJozkV/jvy3pvyW9J+nLYvKPJS2RNE+ju/F7JS0tfswrWxZbdqBhlXbj60LYgeZxPTuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJrjecrNlHkj4c8/q8YtogGtTeBrUvid56VWdvl3Qq9PV69pNWbm+NiAWtNVBiUHsb1L4keutVv3pjNx5IgrADSbQd9jUtr7/MoPY2qH1J9NarvvTW6nd2AP3T9pYdQJ8QdiCJVsJue5Ht39vebXt5Gz10Ynuv7feKYahbHZ+uGEPvsO3tY6bNtv267V3F47hj7LXU20AM410yzHirn13bw5/3/Tu77dMk/UHSQkkjkrZIWhIRO/raSAe290paEBGtn4Bh+68k/VnSvx0fWsv2P0s6EhFPFf9RzoqIfxyQ3p7UKQ7j3VBvnYYZ/3u1+NnVOfx5L9rYst8kaXdE7ImIo5J+KWlxC30MvIh4Q9KREyYvlrS2eL5Wo/9Y+q5DbwMhIg5GxNvF808lHR9mvNXPrqSvvmgj7BdK+uOY1yMarPHeQ9JG22/ZHm67mXGcf3yYreJxTsv9nKjrMN79dMIw4wPz2fUy/HlVbYR9vKFpBun4360R8ZeS/kbSD4vdVUzMTyXN1egYgAclrWqzmWKY8fWSHomIP7XZy1jj9NWXz62NsI9IumjM629KOtBCH+OKiAPF42FJGzT6tWOQHDo+gm7xeLjlfr4SEYci4lhEfCnpZ2rxsyuGGV8v6RcR8UoxufXPbry++vW5tRH2LZKusH2Z7WmSfiDp1Rb6OInts4sfTmT7bEnf1eANRf2qpAeK5w9I+nWLvXzNoAzj3WmYcbX82bU+/HlE9P1P0p0a/UX+fyU93kYPHfr6lqT/Kf7eb7s3Ses0ulv3uUb3iB6UdK6kTZJ2FY+zB6i3f9fo0N7vajRYQy319m2NfjV8V9K24u/Otj+7kr768rlxuiyQBGfQAUkQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/w+hviHnGhsSdAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Escolhendo uma imagem para plotar\n",
    "sample = 10\n",
    "image = x_train[sample]\n",
    "\n",
    "# Plotando a imagem\n",
    "fig = plt.figure\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.max(x_train)\n",
    "x_train = x_train/m\n",
    "x_test = x_test/m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoder na variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot = OneHotEncoder()\n",
    "y_train = hot.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = hot.transform(y_test.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Particionamento de base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28),\n",
       " (12000, 28, 28),\n",
       " (10000, 28, 28),\n",
       " (48000, 10),\n",
       " (12000, 10),\n",
       " (10000, 10))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_treino, x_val, y_treino, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 13)\n",
    "\n",
    "x_treino.shape, x_val.shape, x_test.shape, y_treino.shape, y_val.shape, y_test.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation, Dropout, Flatten,  Conv2D,MaxPool2D, Conv1D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Treinamento - definição de arquitetura\n",
    "1. Definir quantas camadas são necessárias par o problema\n",
    "2. A quantidade de neurônios em cada camada\n",
    "3. A função de ativação de cada camada\n",
    "4. A função de ativação da saída\n",
    "* softmax (saída não binária)\n",
    "* sigmoid (saída binária)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "rede_simples = Sequential()\n",
    "rede_simples.add(Conv2D(filters=1,kernel_size=3,activation='relu',input_shape=[28,28,1]))\n",
    "# rede_simples.add(MaxPool2D(pool_size=(2,2)))\n",
    "rede_simples.add(Flatten())\n",
    "rede_simples.add(Dense(25,activation='relu'))\n",
    "rede_simples.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Definir otimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "rede_simples.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Treinamento\n",
    "\n",
    "1. Adicionar conjuntos de treinamento e validação\n",
    "2. Determinar a quantidade de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = np.expand_dims(x_treino,axis=-1)\n",
    "x_val = np.expand_dims(x_val,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 0.4604 - accuracy: 0.8630 - val_loss: 0.2779 - val_accuracy: 0.9201\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2380 - accuracy: 0.9302 - val_loss: 0.2146 - val_accuracy: 0.9374\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1958 - accuracy: 0.9420 - val_loss: 0.1968 - val_accuracy: 0.9425\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1694 - accuracy: 0.9492 - val_loss: 0.1842 - val_accuracy: 0.9467\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1518 - accuracy: 0.9543 - val_loss: 0.1754 - val_accuracy: 0.9469\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1385 - accuracy: 0.9592 - val_loss: 0.1769 - val_accuracy: 0.9453\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1257 - accuracy: 0.9619 - val_loss: 0.1639 - val_accuracy: 0.9512\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1167 - accuracy: 0.9652 - val_loss: 0.1563 - val_accuracy: 0.9535\n",
      "Epoch 9/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1073 - accuracy: 0.9675 - val_loss: 0.1595 - val_accuracy: 0.9495\n",
      "Epoch 10/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0995 - accuracy: 0.9701 - val_loss: 0.1566 - val_accuracy: 0.9531\n",
      "Epoch 11/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0929 - accuracy: 0.9710 - val_loss: 0.1494 - val_accuracy: 0.9569\n",
      "Epoch 12/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9734 - val_loss: 0.1536 - val_accuracy: 0.9561accuracy: 0.97 - ETA: 0s - loss: 0.087\n",
      "Epoch 13/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0826 - accuracy: 0.9743 - val_loss: 0.1561 - val_accuracy: 0.9571\n",
      "Epoch 14/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0785 - accuracy: 0.9757 - val_loss: 0.1538 - val_accuracy: 0.9573\n",
      "Epoch 15/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0727 - accuracy: 0.9776 - val_loss: 0.1593 - val_accuracy: 0.9564\n",
      "Epoch 16/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9781 - val_loss: 0.1646 - val_accuracy: 0.9550\n",
      "Epoch 17/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0665 - accuracy: 0.9789 - val_loss: 0.1731 - val_accuracy: 0.9549\n",
      "Epoch 18/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0627 - accuracy: 0.9795 - val_loss: 0.1703 - val_accuracy: 0.9532\n",
      "Epoch 19/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0610 - accuracy: 0.9805 - val_loss: 0.1717 - val_accuracy: 0.9563\n",
      "Epoch 20/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 0.1856 - val_accuracy: 0.9532\n",
      "Epoch 21/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0551 - accuracy: 0.9823 - val_loss: 0.1789 - val_accuracy: 0.9563\n",
      "Epoch 22/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0508 - accuracy: 0.9833 - val_loss: 0.1783 - val_accuracy: 0.9557\n",
      "Epoch 23/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.1870 - val_accuracy: 0.9578\n",
      "Epoch 24/100\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 0.1870 - val_accuracy: 0.9579\n",
      "Epoch 25/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.1944 - val_accuracy: 0.9562\n",
      "Epoch 26/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.1952 - val_accuracy: 0.9568\n",
      "Epoch 27/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0411 - accuracy: 0.9869 - val_loss: 0.2057 - val_accuracy: 0.9552\n",
      "Epoch 28/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0404 - accuracy: 0.9858 - val_loss: 0.2144 - val_accuracy: 0.9538\n",
      "Epoch 29/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0401 - accuracy: 0.9873 - val_loss: 0.2306 - val_accuracy: 0.9528\n",
      "Epoch 30/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.2054 - val_accuracy: 0.9568\n",
      "Epoch 31/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0356 - accuracy: 0.9883 - val_loss: 0.2174 - val_accuracy: 0.9547\n",
      "Epoch 32/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 0.2171 - val_accuracy: 0.9555\n",
      "Epoch 33/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 0.2323 - val_accuracy: 0.9552\n",
      "Epoch 34/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.2320 - val_accuracy: 0.9565\n",
      "Epoch 35/100\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.2316 - val_accuracy: 0.9563\n",
      "Epoch 36/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.2419 - val_accuracy: 0.9557\n",
      "Epoch 37/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.2502 - val_accuracy: 0.9551\n",
      "Epoch 38/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0281 - accuracy: 0.9905 - val_loss: 0.2460 - val_accuracy: 0.9546\n",
      "Epoch 39/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0261 - accuracy: 0.9913 - val_loss: 0.2596 - val_accuracy: 0.9530\n",
      "Epoch 40/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.2609 - val_accuracy: 0.9553\n",
      "Epoch 41/100\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.2596 - val_accuracy: 0.9556\n",
      "Epoch 42/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 0.2759 - val_accuracy: 0.9536\n",
      "Epoch 43/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9918 - val_loss: 0.2937 - val_accuracy: 0.9528\n",
      "Epoch 44/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.2752 - val_accuracy: 0.9538\n",
      "Epoch 45/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0221 - accuracy: 0.9924 - val_loss: 0.2965 - val_accuracy: 0.9517\n",
      "Epoch 46/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.3021 - val_accuracy: 0.9543\n",
      "Epoch 47/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.3084 - val_accuracy: 0.9508\n",
      "Epoch 48/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.3031 - val_accuracy: 0.9540\n",
      "Epoch 49/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.3060 - val_accuracy: 0.9527\n",
      "Epoch 50/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.3189 - val_accuracy: 0.9538\n",
      "Epoch 51/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.3266 - val_accuracy: 0.9523\n",
      "Epoch 52/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 0.3161 - val_accuracy: 0.9543\n",
      "Epoch 53/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.3353 - val_accuracy: 0.9507\n",
      "Epoch 54/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.3286 - val_accuracy: 0.9517\n",
      "Epoch 55/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.3520 - val_accuracy: 0.9528\n",
      "Epoch 56/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.3442 - val_accuracy: 0.9534\n",
      "Epoch 57/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.3540 - val_accuracy: 0.9538\n",
      "Epoch 58/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.3454 - val_accuracy: 0.9526\n",
      "Epoch 59/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.3526 - val_accuracy: 0.9540\n",
      "Epoch 60/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.3557 - val_accuracy: 0.9530\n",
      "Epoch 61/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.3787 - val_accuracy: 0.9519\n",
      "Epoch 62/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.3654 - val_accuracy: 0.9532\n",
      "Epoch 63/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.3569 - val_accuracy: 0.9530\n",
      "Epoch 64/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.3745 - val_accuracy: 0.9542\n",
      "Epoch 65/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.3865 - val_accuracy: 0.9515\n",
      "Epoch 66/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.3832 - val_accuracy: 0.9512\n",
      "Epoch 67/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.4114 - val_accuracy: 0.9521\n",
      "Epoch 68/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.3979 - val_accuracy: 0.9528\n",
      "Epoch 69/100\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.3848 - val_accuracy: 0.9532\n",
      "Epoch 70/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.4014 - val_accuracy: 0.9523\n",
      "Epoch 71/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.4049 - val_accuracy: 0.9528\n",
      "Epoch 72/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.4147 - val_accuracy: 0.9520\n",
      "Epoch 73/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.3962 - val_accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.4170 - val_accuracy: 0.9523\n",
      "Epoch 75/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.4418 - val_accuracy: 0.9517\n",
      "Epoch 76/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0119 - accuracy: 0.9954 - val_loss: 0.4265 - val_accuracy: 0.9518\n",
      "Epoch 77/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0099 - accuracy: 0.9964 - val_loss: 0.4422 - val_accuracy: 0.9515\n",
      "Epoch 78/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.4484 - val_accuracy: 0.9519\n",
      "Epoch 79/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.4469 - val_accuracy: 0.9505\n",
      "Epoch 80/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.4471 - val_accuracy: 0.9527\n",
      "Epoch 81/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.4467 - val_accuracy: 0.9526\n",
      "Epoch 82/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.4439 - val_accuracy: 0.9537\n",
      "Epoch 83/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.4727 - val_accuracy: 0.9527\n",
      "Epoch 84/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.4410 - val_accuracy: 0.9512\n",
      "Epoch 85/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.4697 - val_accuracy: 0.9524\n",
      "Epoch 86/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0102 - accuracy: 0.9964 - val_loss: 0.4768 - val_accuracy: 0.9530\n",
      "Epoch 87/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.4786 - val_accuracy: 0.9508\n",
      "Epoch 88/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.4846 - val_accuracy: 0.9531\n",
      "Epoch 89/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0090 - accuracy: 0.9969 - val_loss: 0.4857 - val_accuracy: 0.9517\n",
      "Epoch 90/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.4819 - val_accuracy: 0.9537\n",
      "Epoch 91/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.5022 - val_accuracy: 0.9534\n",
      "Epoch 92/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.4775 - val_accuracy: 0.9527\n",
      "Epoch 93/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0077 - accuracy: 0.9972 - val_loss: 0.4979 - val_accuracy: 0.9503\n",
      "Epoch 94/100\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.4938 - val_accuracy: 0.9532\n",
      "Epoch 95/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.5212 - val_accuracy: 0.9518\n",
      "Epoch 96/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.5089 - val_accuracy: 0.9523\n",
      "Epoch 97/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.4931 - val_accuracy: 0.9542\n",
      "Epoch 98/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.4979 - val_accuracy: 0.9548\n",
      "Epoch 99/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.5178 - val_accuracy: 0.9519\n",
      "Epoch 100/100\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.5507 - val_accuracy: 0.9507\n"
     ]
    }
   ],
   "source": [
    "#### 6. Treinamento\n",
    "\n",
    "historico = rede_simples.fit(x_treino, \n",
    "                             y_treino, \n",
    "                             epochs = 100, \n",
    "                             verbose = 1,\n",
    "                             validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9549"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_test = np.expand_dims(x_test,axis=-1)\n",
    "pred_simples = rede_simples.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test.argmax(1), pred_simples.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = historico.history['loss']\n",
    "val_loss = historico.history['val_loss']\n",
    "epochs = range(len(loss))\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Regularização\n",
    "1. Early Stopping: determinar quando encerrar o treinamento\n",
    "2. Dropout: selecionar neurônios aleatoriamente para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.5146 - val_accuracy: 0.9518\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.5128 - val_accuracy: 0.9534\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.5183 - val_accuracy: 0.9513\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.5249 - val_accuracy: 0.9536\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.5239 - val_accuracy: 0.9528\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.5344 - val_accuracy: 0.9528\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.5289 - val_accuracy: 0.9523\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.5673 - val_accuracy: 0.9509\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.5583 - val_accuracy: 0.9532\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.5495 - val_accuracy: 0.9519\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.5357 - val_accuracy: 0.9524\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.5475 - val_accuracy: 0.9526\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, patience = 10, verbose = 1, mode = 'auto')\n",
    "\n",
    "# Setamos os pesos iniciais iguais à versão antes do treinamento pra ter um comparativo mais real.\n",
    "#rede_simples.set_weights(pesos_iniciais)\n",
    "\n",
    "historico = rede_simples.fit(x_treino, \n",
    "                             y_treino, \n",
    "                             epochs = 150, \n",
    "                             verbose = 1,\n",
    "                             validation_data = (x_val, y_val),\n",
    "                             callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = historico.history['loss']\n",
    "val_loss = historico.history['val_loss']\n",
    "epochs = range(len(loss))\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9572"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_es = rede_simples.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test.argmax(1), pred_es.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 957,    0,    5,    1,    0,    2,    5,    3,    6,    1],\n",
       "       [   0, 1115,    4,    4,    1,    2,    1,    4,    4,    0],\n",
       "       [   7,    2,  990,    9,    7,    1,    3,    5,    8,    0],\n",
       "       [   0,    0,   11,  968,    1,    6,    0,   10,   12,    2],\n",
       "       [   3,    0,    8,    1,  940,    2,    8,    1,    1,   18],\n",
       "       [   6,    1,    2,   25,    3,  806,   19,    3,   18,    9],\n",
       "       [   8,    1,    2,    1,    9,    8,  921,    1,    7,    0],\n",
       "       [   1,    4,   16,    7,    5,    1,    0,  978,    5,   11],\n",
       "       [   2,    2,    3,    4,    3,    4,    9,    3,  938,    6],\n",
       "       [   4,    2,    1,    5,   13,    5,    0,   13,    7,  959]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(1), pred_es.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularização - Dropout\n",
    "\n",
    "* Alterna quais neurônios vão otimizar os pesos a cada rodada do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rede_dropout = Sequential()\n",
    "rede_dropout.add(Conv2D(filters=1,kernel_size=3,activation='relu',input_shape=[28,28,1]))\n",
    "rede_dropout.add(Dropout(0.3))\n",
    "rede_dropout.add(MaxPool2D(pool_size=(2,2)))\n",
    "rede_dropout.add(Flatten())\n",
    "rede_dropout.add(Dense(25,activation='relu'))\n",
    "rede_dropout.add(Dropout(0.3))\n",
    "rede_dropout.add(Dense(10,activation='softmax'))\n",
    "\n",
    "rede_dropout.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7616 - accuracy: 0.7541 - val_loss: 0.3854 - val_accuracy: 0.8992\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4783 - accuracy: 0.8518 - val_loss: 0.3089 - val_accuracy: 0.9183\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4379 - accuracy: 0.8614 - val_loss: 0.2906 - val_accuracy: 0.9245\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4133 - accuracy: 0.8681 - val_loss: 0.2701 - val_accuracy: 0.9302\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3945 - accuracy: 0.8740 - val_loss: 0.2450 - val_accuracy: 0.9337\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3866 - accuracy: 0.8774 - val_loss: 0.2426 - val_accuracy: 0.9333\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3795 - accuracy: 0.8782 - val_loss: 0.2445 - val_accuracy: 0.9364\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3685 - accuracy: 0.8801 - val_loss: 0.2537 - val_accuracy: 0.9332\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3733 - accuracy: 0.8816 - val_loss: 0.2455 - val_accuracy: 0.9382\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3657 - accuracy: 0.8823 - val_loss: 0.2394 - val_accuracy: 0.9373\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3602 - accuracy: 0.8841 - val_loss: 0.2348 - val_accuracy: 0.9366\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3560 - accuracy: 0.8857 - val_loss: 0.2339 - val_accuracy: 0.9363\n",
      "Epoch 13/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3543 - accuracy: 0.8863 - val_loss: 0.2287 - val_accuracy: 0.9397\n",
      "Epoch 14/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3453 - accuracy: 0.8900 - val_loss: 0.2282 - val_accuracy: 0.9397\n",
      "Epoch 15/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3441 - accuracy: 0.8910 - val_loss: 0.2277 - val_accuracy: 0.9418\n",
      "Epoch 16/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3445 - accuracy: 0.8909 - val_loss: 0.2154 - val_accuracy: 0.9393\n",
      "Epoch 17/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3439 - accuracy: 0.8890 - val_loss: 0.2232 - val_accuracy: 0.9406\n",
      "Epoch 18/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3388 - accuracy: 0.8911 - val_loss: 0.2159 - val_accuracy: 0.9424\n",
      "Epoch 19/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3369 - accuracy: 0.8936 - val_loss: 0.2103 - val_accuracy: 0.9427\n",
      "Epoch 20/150\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3373 - accuracy: 0.8927 - val_loss: 0.2189 - val_accuracy: 0.9408\n",
      "Epoch 21/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3360 - accuracy: 0.8927 - val_loss: 0.2069 - val_accuracy: 0.9443\n",
      "Epoch 22/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3307 - accuracy: 0.8936 - val_loss: 0.2105 - val_accuracy: 0.9416\n",
      "Epoch 23/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3311 - accuracy: 0.8934 - val_loss: 0.2115 - val_accuracy: 0.9415\n",
      "Epoch 24/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3335 - accuracy: 0.8941 - val_loss: 0.2075 - val_accuracy: 0.9419\n",
      "Epoch 25/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3360 - accuracy: 0.8924 - val_loss: 0.2099 - val_accuracy: 0.9433\n",
      "Epoch 26/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3304 - accuracy: 0.8940 - val_loss: 0.2159 - val_accuracy: 0.9428\n",
      "Epoch 27/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3239 - accuracy: 0.8968 - val_loss: 0.2040 - val_accuracy: 0.9445\n",
      "Epoch 28/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3286 - accuracy: 0.8963 - val_loss: 0.2019 - val_accuracy: 0.9444\n",
      "Epoch 29/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3203 - accuracy: 0.8969 - val_loss: 0.2010 - val_accuracy: 0.9447\n",
      "Epoch 30/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3231 - accuracy: 0.8971 - val_loss: 0.2050 - val_accuracy: 0.9452\n",
      "Epoch 31/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3210 - accuracy: 0.8978 - val_loss: 0.1968 - val_accuracy: 0.9463\n",
      "Epoch 32/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3218 - accuracy: 0.8982 - val_loss: 0.2039 - val_accuracy: 0.9429\n",
      "Epoch 33/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3183 - accuracy: 0.8974 - val_loss: 0.1956 - val_accuracy: 0.9452\n",
      "Epoch 34/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3263 - accuracy: 0.8969 - val_loss: 0.2074 - val_accuracy: 0.9436\n",
      "Epoch 35/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3240 - accuracy: 0.8967 - val_loss: 0.1989 - val_accuracy: 0.9467\n",
      "Epoch 36/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3236 - accuracy: 0.8962 - val_loss: 0.1928 - val_accuracy: 0.9448\n",
      "Epoch 37/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3246 - accuracy: 0.8962 - val_loss: 0.2009 - val_accuracy: 0.9458\n",
      "Epoch 38/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3243 - accuracy: 0.8967 - val_loss: 0.2065 - val_accuracy: 0.9425\n",
      "Epoch 39/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3194 - accuracy: 0.8991 - val_loss: 0.1997 - val_accuracy: 0.9442\n",
      "Epoch 40/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3196 - accuracy: 0.8992 - val_loss: 0.2081 - val_accuracy: 0.9442\n",
      "Epoch 41/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3182 - accuracy: 0.8978 - val_loss: 0.2046 - val_accuracy: 0.9441\n",
      "Epoch 42/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3161 - accuracy: 0.8984 - val_loss: 0.2008 - val_accuracy: 0.9432\n",
      "Epoch 43/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3204 - accuracy: 0.8971 - val_loss: 0.2050 - val_accuracy: 0.9430\n",
      "Epoch 44/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3150 - accuracy: 0.9007 - val_loss: 0.2080 - val_accuracy: 0.9442\n",
      "Epoch 45/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3154 - accuracy: 0.8995 - val_loss: 0.2004 - val_accuracy: 0.9428\n",
      "Epoch 46/150\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3130 - accuracy: 0.8999 - val_loss: 0.1937 - val_accuracy: 0.9456\n",
      "Epoch 00046: early stopping\n"
     ]
    }
   ],
   "source": [
    "historico = rede_dropout.fit(x_treino, \n",
    "                             y_treino, \n",
    "                             epochs = 150, \n",
    "                             verbose = 1,\n",
    "                             validation_data = (x_val, y_val),\n",
    "                             callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArB0lEQVR4nO3deZgU1b3/8feXYZPNBXBjYIAERRQYYEAURdweQYmi4k+QiEgiglvURMWYKDdertcbb4ImIhLXKHFiNBJU1AQV0ZgoKISIgiKCjooiXGHYhIHv74/TwyxO9/T09Ewz1Z/X8/TTXdupU2fgW6dOnTpl7o6IiDR8jTKdARERSQ8FdBGRiFBAFxGJCAV0EZGIUEAXEYkIBXQRkYhQQJcqmdlzZnZRutfNJDNbbWan1EG6bmbfjf2eYWY/T2bdFPYzxsz+mmo+E6Q7xMyK0p2u1L/Gmc6ApI+ZbS432QL4BtgVm77U3Wclm5a7D6uLdaPO3SemIx0z6wx8BDRx95JY2rOApP+Gkn0U0CPE3VuV/jaz1cAP3X1e5fXMrHFpkBCR6FCTSxYovaQ2sxvMbC3woJntb2bPmNk6M/u/2O/cctvMN7Mfxn6PM7PXzOyO2LofmdmwFNftYmYLzKzYzOaZ2d1m9micfCeTx1vN7O+x9P5qZu3KLb/QzNaY2XozuylB+Qw0s7VmllNu3tlmtjT2e4CZ/cPMvjazz83st2bWNE5aD5nZf5abvi62zWdmNr7SumeY2WIz22Rmn5jZlHKLF8S+vzazzWZ2TGnZltv+WDNbaGYbY9/HJls2iZjZEbHtvzazZWZ2Zrllp5vZu7E0PzWzn8Tmt4v9fb42sw1m9qqZKb7UMxV49jgYOADIAyYQ/vYPxqY7AduA3ybY/mhgBdAO+B/gfjOzFNb9A/Am0BaYAlyYYJ/J5PEC4GLgQKApUBpgegD3xNI/NLa/XKrg7v8EtgAnVUr3D7Hfu4BrYsdzDHAycFmCfBPLw9BYfk4FugGV2++3AGOB/YAzgElmNiK2bHDsez93b+Xu/6iU9gHAs8BdsWP7FfCsmbWtdAzfKptq8twEeBr4a2y7K4FZZnZ4bJX7Cc13rYGjgJdi838MFAHtgYOAnwIaV6SeKaBnj93ALe7+jbtvc/f17v6ku29192JgKnBCgu3XuPvv3H0X8DBwCOE/btLrmlknoD9ws7vvcPfXgDnxdphkHh909/fdfRvwOJAfmz8SeMbdF7j7N8DPY2UQz2PAaAAzaw2cHpuHu7/l7v909xJ3Xw3cW0U+qvL/Yvl7x923EE5g5Y9vvrv/2913u/vS2P6SSRfCCeADd38klq/HgOXA98qtE69sEhkItAL+O/Y3egl4hljZADuBHmbWxt3/z93fLjf/ECDP3Xe6+6uugaLqnQJ69ljn7ttLJ8yshZndG2uS2ES4xN+vfLNDJWtLf7j71tjPVjVc91BgQ7l5AJ/Ey3CSeVxb7vfWcnk6tHzasYC6Pt6+CLXxc8ysGXAO8La7r4nl47BYc8LaWD7+i1Bbr06FPABrKh3f0Wb2cqxJaSMwMcl0S9NeU2neGqBDuel4ZVNtnt29/MmvfLrnEk52a8zsFTM7Jjb/l8BK4K9mtsrMJid3GJJOCujZo3Jt6cfA4cDR7t6Gskv8eM0o6fA5cICZtSg3r2OC9WuTx8/Lpx3bZ9t4K7v7u4TANYyKzS0Qmm6WA91i+fhpKnkgNBuV9wfCFUpHd98XmFEu3epqt58RmqLK6wR8mkS+qku3Y6X27z3puvtCdz+L0Bwzm1Dzx92L3f3H7t6VcJVwrZmdXMu8SA0poGev1oQ26a9j7bG31PUOYzXeRcAUM2saq919L8EmtcnjE8BwMzsudgPzF1T/7/0PwFWEE8efKuVjE7DZzLoDk5LMw+PAODPrETuhVM5/a8IVy3YzG0A4kZRaR2gi6hon7bnAYWZ2gZk1NrPzgR6E5pHaeIPQtn+9mTUxsyGEv1Fh7G82xsz2dfedhDLZBWBmw83su7F7JaXzd1W5B6kzCujZaxqwD/AV8E/g+Xra7xjCjcX1wH8CfyT0l6/KNFLMo7svAy4nBOnPgf8j3LRL5DFgCPCSu39Vbv5PCMG2GPhdLM/J5OG52DG8RGiOeKnSKpcBvzCzYuBmYrXd2LZbCfcM/h7rOTKwUtrrgeGEq5j1wPXA8Er5rjF33wGcSbhS+QqYDox19+WxVS4EVseaniYC34/N7wbMAzYD/wCmu/v82uRFas5030Iyycz+CCx39zq/QhCJOtXQpV6ZWX8z+46ZNYp16zuL0BYrIrWkJ0Wlvh0M/Jlwg7IImOTuizObJZFoUJOLiEhEqMlFRCQiMtbk0q5dO+/cuXOmdi8i0iC99dZbX7l7+6qWZSygd+7cmUWLFmVq9yIiDZKZVX5CeA81uYiIRIQCuohIRCigi4hEhPqhi2SRnTt3UlRUxPbt26tfWTKqefPm5Obm0qRJk6S3UUAXySJFRUW0bt2azp07E//9JJJp7s769espKiqiS5cuSW/XoJpcZs2Czp2hUaPwPUuvyxWpke3bt9O2bVsF872cmdG2bdsaX0k1mBr6rFkwYQJsjb0aYc2aMA0wZkzm8iXS0CiYNwyp/J0aTA39ppvKgnmprVvDfBERaUAB/eOPazZfRPY+69evJz8/n/z8fA4++GA6dOiwZ3rHjh0Jt120aBFXXXVVtfs49thj05LX+fPnM3z48LSkVV8aTEDvVPnlXdXMF5HaS/d9q7Zt27JkyRKWLFnCxIkTueaaa/ZMN23alJKSkrjbFhQUcNddd1W7j9dff712mWzAGkxAnzoVWrSoOK9FizBfRNKv9L7VmjXgXnbfKt2dEcaNG8e1117LiSeeyA033MCbb77JscceS58+fTj22GNZsWIFULHGPGXKFMaPH8+QIUPo2rVrhUDfqlWrPesPGTKEkSNH0r17d8aMGUPp6LJz586le/fuHHfccVx11VXV1sQ3bNjAiBEj6NWrFwMHDmTp0qUAvPLKK3uuMPr06UNxcTGff/45gwcPJj8/n6OOOopXX301vQWWQIO5KVp64/Omm0IzS6dOIZjrhqhI3Uh03yrd/+/ef/995s2bR05ODps2bWLBggU0btyYefPm8dOf/pQnn3zyW9ssX76cl19+meLiYg4//HAmTZr0rT7bixcvZtmyZRx66KEMGjSIv//97xQUFHDppZeyYMECunTpwujRo6vN3y233EKfPn2YPXs2L730EmPHjmXJkiXccccd3H333QwaNIjNmzfTvHlzZs6cyWmnncZNN93Erl272Fq5EOtQgwnoEP4RKYCL1I/6vG913nnnkZOTA8DGjRu56KKL+OCDDzAzdu7cWeU2Z5xxBs2aNaNZs2YceOCBfPHFF+Tm5lZYZ8CAAXvm5efns3r1alq1akXXrl339O8ePXo0M2fOTJi/1157bc9J5aSTTmL9+vVs3LiRQYMGce211zJmzBjOOecccnNz6d+/P+PHj2fnzp2MGDGC/Pz82hRNjTSYJhcRqV/1ed+qZcuWe37//Oc/58QTT+Sdd97h6aefjtsXu1mzZnt+5+TkVNn+XtU6qbzUp6ptzIzJkydz3333sW3bNgYOHMjy5csZPHgwCxYsoEOHDlx44YX8/ve/r/H+UqWALiJVytR9q40bN9KhQwcAHnroobSn3717d1atWsXq1asB+OMf/1jtNoMHD2ZW7ObB/PnzadeuHW3atOHDDz+kZ8+e3HDDDRQUFLB8+XLWrFnDgQceyCWXXMIPfvAD3n777bQfQzwK6CJSpTFjYOZMyMsDs/A9c2bdN3tef/313HjjjQwaNIhdu3alPf199tmH6dOnM3ToUI477jgOOugg9t1334TbTJkyhUWLFtGrVy8mT57Mww8/DMC0adM46qij6N27N/vssw/Dhg1j/vz5e26SPvnkk/zoRz9K+zHEk7F3ihYUFLhecCFSv9577z2OOOKITGcj4zZv3kyrVq1wdy6//HK6devGNddck+lsfUtVfy8ze8vdC6paXzV0Eck6v/vd78jPz+fII49k48aNXHrppZnOUlo0qF4uIiLpcM011+yVNfLaUg1dRCQiFNBFRCJCAV1EJCIU0EVEIkIBXUTqzZAhQ3jhhRcqzJs2bRqXXXZZwm1KuziffvrpfP31199aZ8qUKdxxxx0J9z179mzefffdPdM333wz8+bNq0Huq7Y3DbOrgC4i9Wb06NEUFhZWmFdYWJjUAFkQRkncb7/9Utp35YD+i1/8glNOOSWltPZWCugiUm9GjhzJM888wzfffAPA6tWr+eyzzzjuuOOYNGkSBQUFHHnkkdxyyy1Vbt+5c2e++uorAKZOncrhhx/OKaecsmeIXQh9zPv370/v3r0599xz2bp1K6+//jpz5szhuuuuIz8/nw8//JBx48bxxBNPAPDiiy/Sp08fevbsyfjx4/fkr3Pnztxyyy307duXnj17snz58oTHl+lhdpPqh25mQ4E7gRzgPnf/70rLrwNKHwhuDBwBtHf3DbXOoYjUiauvhiVL0ptmfj5MmxZ/edu2bRkwYADPP/88Z511FoWFhZx//vmYGVOnTuWAAw5g165dnHzyySxdupRevXpVmc5bb71FYWEhixcvpqSkhL59+9KvXz8AzjnnHC655BIAfvazn3H//fdz5ZVXcuaZZzJ8+HBGjhxZIa3t27czbtw4XnzxRQ477DDGjh3LPffcw9VXXw1Au3btePvtt5k+fTp33HEH9913X9zjy/Qwu9XW0M0sB7gbGAb0AEabWY/y67j7L909393zgRuBVxTMRaQq5Ztdyje3PP744/Tt25c+ffqwbNmyCs0jlb366qucffbZtGjRgjZt2nDmmWfuWfbOO+9w/PHH07NnT2bNmsWyZcsS5mfFihV06dKFww47DICLLrqIBQsW7Fl+zjnnANCvX789A3rF89prr3HhhRcCVQ+ze9ddd/H111/TuHFj+vfvz4MPPsiUKVP497//TevWrROmnYxkaugDgJXuvgrAzAqBs4B4pT0aeKzWOROROpWoJl2XRowYwbXXXsvbb7/Ntm3b6Nu3Lx999BF33HEHCxcuZP/992fcuHFxh80tZWZVzh83bhyzZ8+md+/ePPTQQ8yfPz9hOtWNZ1U6BG+8IXqrS6t0mN0zzjiDuXPnMnDgQObNm7dnmN1nn32WCy+8kOuuu46xY8cmTL86ybShdwA+KTddFJtXVcZbAEOBb79eRESE8Iq4IUOGMH78+D21802bNtGyZUv23XdfvvjiC5577rmEaQwePJinnnqKbdu2UVxczNNPP71nWXFxMYcccgg7d+7cM+QtQOvWrSkuLv5WWt27d2f16tWsXLkSgEceeYQTTjghpWPL9DC7ydTQqzoNxjulfQ/4e7zmFjObAEwA6KS3O4tkrdGjR3POOefsaXrp3bs3ffr04cgjj6Rr164MGjQo4fZ9+/bl/PPPJz8/n7y8PI4//vg9y2699VaOPvpo8vLy6Nmz554gPmrUKC655BLuuuuuPTdDAZo3b86DDz7IeeedR0lJCf3792fixIkpHdeUKVO4+OKL6dWrFy1atKgwzO7LL79MTk4OPXr0YNiwYRQWFvLLX/6SJk2a0KpVq7S8CKPa4XPN7BhgirufFpu+EcDdb6ti3aeAP7n7H6rbsYbPFal/Gj63YamL4XMXAt3MrIuZNQVGAXMqr2Rm+wInAH+pca5FRKTWqm1ycfcSM7sCeIHQbfEBd19mZhNjy2fEVj0b+Ku7b6mz3IqISFxJ9UN397nA3ErzZlSafgh4KF0ZE5G64e5xe4jI3iOVt8npSVGRLNK8eXPWr1+fUrCQ+uPurF+/nubNm9doO72xSCSL5ObmUlRUxLp16zKdFalG8+bNyc3NrdE2CugiWaRJkyZ06dIl09mQOqImFxGRiFBAFxGJCAV0EZGIUEAXEYkIBXQRkYhQQBcRiQgFdBGRiFBAFxGJCAV0EZGIUEAXEYkIBXQRkYhQQBcRiQgFdBGRiFBAFxGJCAV0EZGIUEAXEYkIBXQRkYhQQBcRiQgFdBGRiFBAFxGJCAV0EZGIUEAXEYkIBXQRkYhIKqCb2VAzW2FmK81scpx1hpjZEjNbZmavpDebIiJSncbVrWBmOcDdwKlAEbDQzOa4+7vl1tkPmA4MdfePzezAOsqviIjEkUwNfQCw0t1XufsOoBA4q9I6FwB/dvePAdz9y/RmU0REqpNMQO8AfFJuuig2r7zDgP3NbL6ZvWVmY6tKyMwmmNkiM1u0bt261HIsIiJVSiagWxXzvNJ0Y6AfcAZwGvBzMzvsWxu5z3T3AncvaN++fY0zKyIi8VXbhk6okXcsN50LfFbFOl+5+xZgi5ktAHoD76cllyIiUq1kaugLgW5m1sXMmgKjgDmV1vkLcLyZNTazFsDRwHvpzaqIiCRSbQ3d3UvM7ArgBSAHeMDdl5nZxNjyGe7+npk9DywFdgP3ufs7dZlxERGpyNwrN4fXj4KCAl+0aFFG9i0i0lCZ2VvuXlDVMj0pKiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiISEQroIiIRkVRAN7OhZrbCzFaa2eQqlg8xs41mtiT2uTn9WRURkUQaV7eCmeUAdwOnAkXAQjOb4+7vVlr1VXcfXgd5FBGRJCRTQx8ArHT3Ve6+AygEzqrbbImISE0lE9A7AJ+Umy6KzavsGDP7l5k9Z2ZHVpWQmU0ws0VmtmjdunUpZFdEROJJJqBbFfO80vTbQJ679wZ+A8yuKiF3n+nuBe5e0L59+xplVEREEksmoBcBHctN5wKflV/B3Te5++bY77lAEzNrl7ZciohItZIJ6AuBbmbWxcyaAqOAOeVXMLODzcxivwfE0l2f7syKiEh81fZycfcSM7sCeAHIAR5w92VmNjG2fAYwEphkZiXANmCUu1dulhERkTqUVD90d5/r7oe5+3fcfWps3oxYMMfdf+vuR7p7b3cf6O6v12WmqzJrFnTuDI0ahe9Zs+o7ByIimVVtDb0hmDULJkyArVvD9Jo1YRpgzJjM5UtEpD5F4tH/m24qC+altm4N80VEskUkAvrHH9dsvohIFEUioHfqVLP5IiJRFImAPnUqtGhRcV6LFmG+iEi2iERAHzMGZs6EvDwwC98zZ+qGqIhkl0j0coEQvBXARSSbRaKGLiIiCugiIpGhgC4iEhEK6CIiEaGALiISEQroIiIRkRUBXSMxikg2iEw/9Hg0EqOIZIvI19A1EqOIZIvIB3SNxCgi2SLyAV0jMYpItoh8QNdIjCKSLSIf0DUSo4hki8j3cgGNxCgi2SHyNfTqqI+6iERFVtTQ41EfdRGJkqyuoauPuohESVYHdPVRF5EoyeqArj7qIhIlSQV0MxtqZivMbKWZTU6wXn8z22VmI9OXxbqjPuoiEiXVBnQzywHuBoYBPYDRZtYjznq3Ay+kO5N1RX3URSRKkqmhDwBWuvsqd98BFAJnVbHelcCTwJdpzF+dGzMGVq+G3bvDd2kwV3dGEWlokgnoHYBPyk0XxebtYWYdgLOBGYkSMrMJZrbIzBatW7eupnmtN6XdGdesAfey7owK6iKyN0smoFsV87zS9DTgBnfflSghd5/p7gXuXtC+ffsks1j/1J1RRBqiZAJ6EdCx3HQu8FmldQqAQjNbDYwEppvZiHRkMBOq686o5hgR2Rsl86ToQqCbmXUBPgVGAReUX8Hdu5T+NrOHgGfcfXb6slm/OnUKzSxVzdfTpSKyt6q2hu7uJcAVhN4r7wGPu/syM5toZhPrOoOV/fWv0KsX1GUTfKLujNU1x6j2LiKZYu6Vm8PrR0FBgS9atKjG273+OgwaBH/6E4ysw97us2aFIP3xx6FmPnVqqIE3ahRulFZmBo88UrH2DuFEoK6QIpIuZvaWuxdUtazBPSnavz+0bAkvv1y3+4nXnTHR06W1uZmqmr2I1FaDC+hNmsDxx9d9QI8nUXNMqmPDqJukiKRDgwvoACeeCO+9B2vX1v++Ez1dWt3YMPFq4eomKSLp0GADOsD8+ZnZf7zmmES190S18EQ1ezXFiEiyGmRA79MH2rTJXLNLPIlq74lq4fFq9gccoKYYEUlegwzojRvD4MF7X0CH+LX3RLXweDV7UBdJEUlegwzoEJpdPvgAPv000zlJTqL29Xg1+w0bqt6mtCkmUe1dwV4k+zTogA57Zy29KtWNvV5VzT7VLpIK9iLZqcEG9N69Yf/9G05AT2Xs9VS7SNYm2ItIw9XgnhQt7+yzYckS+Oij9ORpbxTvidXOnasebyYvL6wb72nWeOPU5OWFKwMR2btF6knR8k48MQShKAeiVLpIJmqqSbWLZF0sE5E0c/eMfPr16+e1tXSpO7g/8ECtk2qQHn3UPS/P3Sx8P/po2fwWLULZlH5atChbv/z80k/btvG3SZReqstEJDXAIo8TVxt0QN+1y71dO/cLL6x1UpFT02Dftm3VgT4vL/5JoDbL4uVPRBKLbEB3dz/vPPfcXPfdu9OSXFaoKpiaVR18zdK/rPQkEq/mnijYp7qsPspQpD5EOqBPnx6O4oMP0pJc1qqLWni8ZTk5iWvue0vzTipNWiJ1LdIB/b33wlHMnJmW5LJWXQTSeMvi1dpLA2d9Nu+k8z5EXl7iNEXSIdIBffdu94MPdh89Oi3JZbW6aOqoalmigFifzTupBu1E+Ui19q6TgCQr0gHdPQTzgw9WO3pDkWogTXfzTqpBO91XCg2lCSdR/uujIiBB5AP6zJnhSN59N21JSh1LJbilu3kn1aCdKB+pXClU14STajmmM1jGO+ZJk9Tdtb5FPqB/8EE4krvvTluSkkH11byTatBOlI9UrhQSnVgS7SvdQTbdx7W33A+pblkq/w4zKfIBfffu0HVx5Mi0JSkRUZuaYDprsomuFFI9saQ7yKZ65RHvuPaW+yGp/J1r82+jrk8EkQ/o7uHhonbtwsNGIuXV93++ml4ppPvmbKpBtj7vUewt+4pX9oketKvvSkJlWRHQH3ggHM3SpWlNViQtUv2PnkoArosbwXtDG3qqJ6pUyjDRvuqqGS9ZWRHQP/ooHM2dd6Y1WZG0SaV2lkqASDXIVndzNtO9XOqiTb6mVznVnfhSvQKqiawI6O7unTu7jxiR9mRFMibVmn0qgXRv711SF71m4gXZRIPVpfvkUXrzO1lZE9B/+EP35s3dX3wx7UmLZEx99rbYW3t2lEr31UB1J4JUtqmL7qnl1TqgA0OBFcBKYHIVy88ClgJLgEXAcdWlWRcB/bPP3I880r1ZM/c5c9KevIhEULq7NNb1FVCigF7tG4vMLAd4HzgVKAIWAqPd/d1y67QCtri7m1kv4HF3754o3XS8sagq69fD0KGweDH8/vdwwQVp34WISErivYGsJhK9sahxEtsPAFa6+6pYYoWEGvmegO7um8ut3xJIfJaoQ23bwosvwplnwve/D5s2wcSJmcqNiEiZMWNqHsBrIplX0HUAPik3XRSbV4GZnW1my4FngfFVJWRmE8xskZktWrduXSr5TUqbNvDcc3D66TBpEtx+e53tSkRkr5FMQLcq5n2rBu7uT8WaWUYAt1aVkLvPdPcCdy9o3759jTJaU/vsA089BaNGweTJ8NOfhlYrEZGoSqbJpQjoWG46F/gs3sruvsDMvmNm7dz9q9pmsDaaNIFHH4XWreG222DrVvj1r8GqOkWJiDRwyQT0hUA3M+sCfAqMAircajSz7wIfxm6K9gWaAuvTndlU5OTAvfdCixZw553QsmW4ESEiEjXVBnR3LzGzK4AXgBzgAXdfZmYTY8tnAOcCY81sJ7ANON+r6z5Tj8xCzXzrVviv/wo19smTM50rEZH0SqaGjrvPBeZWmjej3O/bgb361qMZ3HMPbNkCN94Ygvrll2c6VyIi6ZNUQI+KnBx46CHYvBmuuAJatYKLLsp0rkRE0iOZXi6R0qQJ/PGPcPLJMH48PPlkpnMkIpIeWRfQAZo3h7/8BQYOhNGj4fnnM50jEZHay8qADqG3y7PPwlFHwdlnw+uvZzpHIiK1k7UBHWC//eCFFyA3F0aOhLVrM50jEZHUZXVAB2jfHv78Z/j6azj/fNi5M9M5EhFJTdYHdICePeF3v4MFC0KXRhGRhkgBPWbMGLjsMvjf/4Unnsh0bkREak4BvZxf/QqOPjp0Z1yxItO5ERGpGQX0cpo1gz/9KXyfc054ACldvv46jCHTqROceGLo/15Skr70RUQU0Cvp2BEeewyWL4dLLqn9kLtr18INN4RA/rOfwWGHwerVoVdNly5hbJkvv0xL1kUkyymgV+GUU+DWW6GwEH7zm9TS+Oij0CbfuTPccUd42cbixTBvHqxcGR5sOuKI8Dqqjh1h7Fh4802N2S4iqav2naJ1pa7eKZouu3fDiBHh4aOuXSEvr+zTqVP43nffULteu7bi57PPwoNKOTlhrJjrr4fvfrfq/SxfDnffXTbGTJcuYb8jRsCxx0LjrBptR0Sqk+idogroCWzcGHq9rFgBa9aET6KHj9q0gYMPDp+jj4arr4ZDD01uX5s2hTFmZs8OtfgdO8L7Ub/3vRDcTz01jOkuItlNAT2Ntm+HoqIQ3DdtgoMOCgH8oIPCcALpUFwcnmCdPRueeSacWJo2hQED4Ljj4PjjQ+19v/3Ssz8RaTgU0BuwnTvDA0/PPQevvQZvvRV6x5hBr14hwB91VDiZVP60ahWahpo2zfRRiEi6JAroaqHdyzVpEob6PfnkML1lC7zxRgjur74a2t63bIm/fcuWcMIJocnm1FOhRw+9U1UkqhTQG5iWLeGkk8IHQm193boQ1Es/mzeH702bQs+Zv/0N5sbeN3XooSGwn3RSGMemadOqP82affvTSH2iRPZqCugNXOPGcMgh8ZeXvpFpzZoQ2P/2t9Au//DDNd9Xkyaheee3vw1t+CKyd1EbehbavTt0lywuDr1pyn+++SZ8yv8u/WzfDn/4A3z8MUycCLfdVv2N2U2bQq+d/PzQ/VNEakdt6FJBo0ahLT0VN90EN98Md94ZHo666y4499yK7fLu4ebtvfeGp25L2/hPOAHGjQtPybZqVevDEJFK1CoqNdKqVRjE7M03Q3fN886DM88MtfZNm0IQ79cP+vcPtfnzzw819KlTwwNXF18cunhedBG8/HK4WkjWzp2hr/5JJ4XRMYuK6u44RRoiNblIykpKQk395pvLauhbtkDv3nDppXDBBeFp2lLu8I9/hPb7wsJwAujYMTw8NWxYGLSsqr78GzaE8ep/+9sQxLt2DSeHxo3DEA1XXLF3PFG7cye88kq4cnn77TAW0EUXqVeRpJf6oUudWr06BPVmzUIQ69+/+iC2bVt4cOqxx+DFF2Hr1rD9CSeE4H766aH2ftdd4QSwdWuomV9zTVi2ejVceWXovZOfDzNmhKdzE3EPJ5zi4m9/mjSBvn3hwANrduwbN4ZnBObMCXnZuBH22SecqN5/PzwENn16uJkskg4K6LJX++absoennnsu3LAt1bRpaF65+urwIFV57vDUU3DVVaHGfumlYfTK/fcPXTn/9S9YsqTss2JF9UMWd+oUTkgFBWXfLVqEK4PVq8uGgFi9Gj78EP75z1Azb98+XGmcdVYY3K15c3jwwTCOz8aN4UR0yy26d1DXduwIf/tDD637K6PSzgJt2tTtfiqrdUA3s6HAnUAOcJ+7/3el5WOAG2KTm4FJ7v6vRGkqoEs8H30Uartbt4ZRKA86KPH6xcUhWN55ZwjmzZvDp5+WLe/YMTQDHXUUHHAAtG797c+WLbBoUfgsXBiCdalGjSq29ZuFrqJ5eeFJ3bPOgoEDw2BslX31VXit4X33hZeRT5sWxtpPZ7ApKan7Jif3cDX161+HE91VV0H37nWzr+3bQ9PVq6+G10MOH179sBpr14b7NzNmhN9t2oQKQK9eIY1evcLfP5Xgu2FDqGS89174Lv2sWhX+jsOHww9/CEOH1k/TX60CupnlAO8DpwJFwEJgtLu/W26dY4H33P3/zGwYMMXdE14AK6BLui1eHNrUW7UKzTD5+SGQt21b87Q2bCgL8Nu3h2GQ8/LCd25uaB6qiX/8AyZNClcNxx4bgktuLnToUPG7TZvEwX7TpnCcCxeW5W/VqvAk8eWXh+BSXVB55x145JHQ7DVhQvXNQe++G+5TvPxy2Xj+O3aEprGrrw4PqtX2BLVqVbg6mzs37GfbtrJlLVuGG++jRsFpp1Us+0WLQrNcYWG4Uho2LKyzYgUsXRo+xcVl63ftGm7a9+sXmtj69q3472PbtlC+b7wRbvy/8UaoYJRq1gwOPzyczLp3D+v//vfwxRfhb3jxxeGNZ1261K48EkkU0HH3hB/gGOCFctM3AjcmWH9/4NPq0u3Xr5+LZJOdO92nTXPv08e9fXv3UO+t+GnSxH3//d07dnQ/4gj3/v3dTzzR/fTT3bt3dzcrWzcvz/3cc92vucY9NzfM69TJ/bbb3L/8suK+1651//Wvw77BvXFj92bNwu+TTnJ/6in3kpKK2xQXu19/fVh3//3d77knrLN2rft//If7QQeF7Xv0cL/3XvctW2pWHqtWuU+e7H744WXH1LWr+xVXuM+dG/b/8svuEya4H3BAWL7ffu7jx7vPmOF+zDFhXqtW7lde6b5ixbf3sXu3++rV7nPmuN96ayivLl0qlnlenvuZZ7r36xeOtXR+p07uI0e6/8//uD/7rPuHH367jNzdd+wI5Xf66e6NGoVtTznFfdascAzpBizyOHE1mRr6SGCou/8wNn0hcLS7XxFn/Z8A3UvXr7RsAjABoFOnTv3WrFlT/elIJKK++Sa0/X/6aWijLyqC9evLhm7YvLnss2VLqMEXFJR92rcvS6ukBJ5+OvQEeumlcO9h1CgYMiS87vD552HXrrDd2LFhWaNGoSno7rvhk0/C1cfll8MPfhDSuPrqkKeLL4bbb6+4v9L8P/54aIZZvDg8ZFY63PNpp1XdTLJrVxhJdPr0UBtv1Cjc7D7jjFC77tat6tr+zp3hKefCwnDfZPNm+M53wo3xceMq9qZKxoYNIc9vvRV6JC1dGtrdjz46jGo6YEDiJ7Dj+eSTML7S/feHey377BPKZNSocHzNm9c8zcpqW0M/j9BuXjp9IfCbOOueCLwHtK0uXdXQRerGsmXul18eaq7g3qFDqAkvW1b1+jt3uj/xhPvgwWW1d3Dv1cv9tdeq39/u3e4LFriPHRtq8uDevLn7977nfv/94Wph3Tr3228vqx0ffLD7zTe7f/JJzY9v61b3xYvdd+2q+bb1ZdeuUCaXXVZ2Nda6dSijuXNDrT5V1LKGfgyhTfy02PSNsRPBbZXW6wU8BQxz9/erO8uoDV2kbm3aBB98EO4lVHXDtir/+lfondOtW+g1VNObfCUlYSTQ2bPDZ82aUAtv3Di0u59wQng144gR2TOsc0lJuOIpLIQ//zn0err88nA1lYra3hRtTLgpejLwKeGm6AXuvqzcOp2Al4Cx7v56MplSQBeJNvdwgpg9OzSRXHwxHHlkpnOVWd98E5qc8vLCDftU1GosF3cvMbMrgBcI3RYfcPdlZjYxtnwGcDPQFphuoQGsJN4ORSQ7mJX1NpKgWbPQY6eu6MEiEZEGJFENXYNziYhEhAK6iEhEKKCLiESEArqISEQooIuIRIQCuohIRCigi4hERMb6oZvZOiDV0bnaAV+lMTsNncqjIpVHGZVFRVEojzx3b1/VgowF9Nows0V6ErWMyqMilUcZlUVFUS8PNbmIiESEArqISEQ01IA+M9MZ2MuoPCpSeZRRWVQU6fJokG3oIiLybQ21hi4iIpUooIuIRESDC+hmNtTMVpjZSjObnOn81Dcze8DMvjSzd8rNO8DM/mZmH8S+989kHuuLmXU0s5fN7D0zW2ZmP4rNz9byaG5mb5rZv2Ll8R+x+VlZHgBmlmNmi83smdh0pMuiQQV0M8sB7gaGAT2A0WbWI7O5qncPAUMrzZsMvOju3YAXY9PZoAT4sbsfAQwELo/9e8jW8vgGOMndewP5wFAzG0j2lgfAjwgvri8V6bJoUAEdGACsdPdV7r4DKATOynCe6pW7LwA2VJp9FvBw7PfDwIj6zFOmuPvn7v527Hcx4T9uB7K3PNzdN8cmm8Q+TpaWh5nlAmcA95WbHemyaGgBvQPwSbnpoti8bHeQu38OIcgBB2Y4P/XOzDoDfYA3yOLyiDUxLAG+BP7m7tlcHtOA64Hd5eZFuiwaWkC3Kuap32WWM7NWwJPA1e6+KdP5ySR33+Xu+UAuMMDMjspwljLCzIYDX7r7W5nOS31qaAG9COhYbjoX+CxDedmbfGFmhwDEvr/McH7qjZk1IQTzWe7+59jsrC2PUu7+NTCfcL8lG8tjEHCmma0mNM2eZGaPEvGyaGgBfSHQzcy6mFlTYBQwJ8N52hvMAS6K/b4I+EsG81JvzMyA+4H33P1X5RZla3m0N7P9Yr/3AU4BlpOF5eHuN7p7rrt3JsSJl9z9+0S8LBrck6JmdjqhbSwHeMDdp2Y2R/XLzB4DhhCGAf0CuAWYDTwOdAI+Bs5z98o3TiPHzI4DXgX+TVk76U8J7ejZWB69CDf6cgiVtcfd/Rdm1pYsLI9SZjYE+Im7D496WTS4gC4iIlVraE0uIiIShwK6iEhEKKCLiESEArqISEQooIuIRIQCuohIRCigi4hExP8HdNQg4jSIWqIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = historico.history['loss']\n",
    "val_loss = historico.history['val_loss']\n",
    "epochs = range(len(loss))\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_dropout = rede_dropout.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test.argmax(1), pred_dropout.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 965,    0,    2,    0,    1,    1,    5,    4,    2,    0],\n",
       "       [   0, 1116,    4,    0,    1,    2,    7,    0,    5,    0],\n",
       "       [   8,    1,  978,   14,    4,    1,    5,   10,   10,    1],\n",
       "       [   0,    1,    6,  957,    0,   21,    1,   10,   11,    3],\n",
       "       [   0,    1,    5,    0,  947,    0,    6,    1,    2,   20],\n",
       "       [   6,    0,    0,   15,    2,  831,    8,    4,   18,    8],\n",
       "       [  11,    3,    1,    0,    4,    4,  932,    0,    3,    0],\n",
       "       [   3,    8,   16,   15,    2,    0,    0,  963,    3,   18],\n",
       "       [   7,    2,    8,    5,    7,    1,    3,    3,  932,    6],\n",
       "       [   4,    5,    0,   12,   17,    7,    0,    8,    4,  952]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.argmax(1), pred_dropout.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x_train.mean(axis=0)\n",
    "x_train -= mean\n",
    "std = x_train.std(axis=0)\n",
    "x_train /= std\n",
    "\n",
    "x_test -= mean\n",
    "x_test /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323, 13), (81, 13), (102, 13), (323,), (81,), (102,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_treino, x_val, y_treino, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 13)\n",
    "\n",
    "x_treino.shape, x_val.shape, x_test.shape, y_treino.shape, y_val.shape, y_test.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(3,1, activation='relu', input_shape=(len(x_train[1]),1)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 13, 3)             6         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 13, 64)            256       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 13, 1)             65        \n",
      "=================================================================\n",
      "Total params: 327\n",
      "Trainable params: 327\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = np.expand_dims(x_treino,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = (x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "6/6 [==============================] - 1s 23ms/step - loss: 567.6996 - mae: 21.9914 - val_loss: 635.4394 - val_mae: 23.4742\n",
      "Epoch 2/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 562.4835 - mae: 21.8726 - val_loss: 630.8491 - val_mae: 23.3767\n",
      "Epoch 3/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 558.2338 - mae: 21.7768 - val_loss: 626.2439 - val_mae: 23.2784\n",
      "Epoch 4/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 553.9417 - mae: 21.6766 - val_loss: 621.9752 - val_mae: 23.1869\n",
      "Epoch 5/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 549.8588 - mae: 21.5828 - val_loss: 617.4418 - val_mae: 23.0892\n",
      "Epoch 6/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 545.5451 - mae: 21.4812 - val_loss: 612.4454 - val_mae: 22.9811\n",
      "Epoch 7/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 540.8054 - mae: 21.3722 - val_loss: 607.0807 - val_mae: 22.8643\n",
      "Epoch 8/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 535.7786 - mae: 21.2534 - val_loss: 601.8362 - val_mae: 22.7495\n",
      "Epoch 9/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 530.8029 - mae: 21.1345 - val_loss: 596.6349 - val_mae: 22.6350\n",
      "Epoch 10/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 525.7914 - mae: 21.0165 - val_loss: 590.9434 - val_mae: 22.5093\n",
      "Epoch 11/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 520.3600 - mae: 20.8877 - val_loss: 584.5659 - val_mae: 22.3676\n",
      "Epoch 12/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 514.4357 - mae: 20.7424 - val_loss: 578.1090 - val_mae: 22.2230\n",
      "Epoch 13/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 508.3859 - mae: 20.5966 - val_loss: 572.2573 - val_mae: 22.0911\n",
      "Epoch 14/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 502.7382 - mae: 20.4596 - val_loss: 565.8170 - val_mae: 21.9449\n",
      "Epoch 15/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 496.5791 - mae: 20.3092 - val_loss: 558.3626 - val_mae: 21.7745\n",
      "Epoch 16/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 489.6405 - mae: 20.1377 - val_loss: 551.1631 - val_mae: 21.6085\n",
      "Epoch 17/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 482.8741 - mae: 19.9646 - val_loss: 543.9456 - val_mae: 21.4407\n",
      "Epoch 18/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 475.9955 - mae: 19.7931 - val_loss: 536.0222 - val_mae: 21.2550\n",
      "Epoch 19/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 468.5444 - mae: 19.6047 - val_loss: 527.3618 - val_mae: 21.0500\n",
      "Epoch 20/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 460.5121 - mae: 19.4009 - val_loss: 518.5109 - val_mae: 20.8384\n",
      "Epoch 21/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 452.3864 - mae: 19.1883 - val_loss: 510.5676 - val_mae: 20.6482\n",
      "Epoch 22/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 444.8603 - mae: 18.9916 - val_loss: 501.2787 - val_mae: 20.4238\n",
      "Epoch 23/150\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 436.3214 - mae: 18.7666 - val_loss: 492.3827 - val_mae: 20.2069\n",
      "Epoch 24/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 428.0039 - mae: 18.5457 - val_loss: 483.6934 - val_mae: 19.9928\n",
      "Epoch 25/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 419.8037 - mae: 18.3259 - val_loss: 474.1530 - val_mae: 19.7552\n",
      "Epoch 26/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 410.9224 - mae: 18.0849 - val_loss: 464.5519 - val_mae: 19.5128\n",
      "Epoch 27/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 402.0219 - mae: 17.8377 - val_loss: 453.7607 - val_mae: 19.2372\n",
      "Epoch 28/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 392.2140 - mae: 17.5656 - val_loss: 443.8521 - val_mae: 18.9806\n",
      "Epoch 29/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 383.0589 - mae: 17.3052 - val_loss: 433.8315 - val_mae: 18.7192\n",
      "Epoch 30/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 373.7859 - mae: 17.0408 - val_loss: 422.8025 - val_mae: 18.4275\n",
      "Epoch 31/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 363.7406 - mae: 16.7505 - val_loss: 411.1002 - val_mae: 18.1129\n",
      "Epoch 32/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 353.2899 - mae: 16.4440 - val_loss: 400.9337 - val_mae: 17.8363\n",
      "Epoch 33/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 343.9426 - mae: 16.1639 - val_loss: 390.6397 - val_mae: 17.5518\n",
      "Epoch 34/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 334.4865 - mae: 15.8757 - val_loss: 378.9690 - val_mae: 17.2218\n",
      "Epoch 35/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 324.0825 - mae: 15.5562 - val_loss: 368.4948 - val_mae: 16.9230\n",
      "Epoch 36/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 314.5065 - mae: 15.2597 - val_loss: 357.7288 - val_mae: 16.6119\n",
      "Epoch 37/150\n",
      "6/6 [==============================] - ETA: 0s - loss: 262.9639 - mae: 13.75 - 0s 5ms/step - loss: 304.7379 - mae: 14.9558 - val_loss: 346.3464 - val_mae: 16.2765\n",
      "Epoch 38/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 294.5862 - mae: 14.6277 - val_loss: 335.2039 - val_mae: 15.9416\n",
      "Epoch 39/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 284.6345 - mae: 14.2976 - val_loss: 323.2300 - val_mae: 15.5745\n",
      "Epoch 40/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 274.0581 - mae: 13.9530 - val_loss: 312.1847 - val_mae: 15.2297\n",
      "Epoch 41/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 264.2891 - mae: 13.6148 - val_loss: 300.1407 - val_mae: 14.8447\n",
      "Epoch 42/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 253.8362 - mae: 13.2588 - val_loss: 289.3385 - val_mae: 14.4902\n",
      "Epoch 43/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 244.3826 - mae: 12.9326 - val_loss: 278.2584 - val_mae: 14.1177\n",
      "Epoch 44/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 234.6806 - mae: 12.5929 - val_loss: 268.8584 - val_mae: 13.7955\n",
      "Epoch 45/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 226.4620 - mae: 12.2919 - val_loss: 257.4854 - val_mae: 13.3981\n",
      "Epoch 46/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 216.8004 - mae: 11.9438 - val_loss: 246.7423 - val_mae: 13.0148\n",
      "Epoch 47/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 207.7150 - mae: 11.6017 - val_loss: 236.5459 - val_mae: 12.6444\n",
      "Epoch 48/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 199.0946 - mae: 11.2769 - val_loss: 226.6819 - val_mae: 12.2787\n",
      "Epoch 49/150\n",
      "6/6 [==============================] - ETA: 0s - loss: 228.6677 - mae: 12.10 - 0s 5ms/step - loss: 190.8417 - mae: 10.9605 - val_loss: 216.3538 - val_mae: 11.8907\n",
      "Epoch 50/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 182.3027 - mae: 10.6272 - val_loss: 204.7091 - val_mae: 11.4400\n",
      "Epoch 51/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 173.4020 - mae: 10.2668 - val_loss: 196.5286 - val_mae: 11.1175\n",
      "Epoch 52/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 166.7440 - mae: 9.9878 - val_loss: 188.2782 - val_mae: 10.7863\n",
      "Epoch 53/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 160.1239 - mae: 9.7169 - val_loss: 180.9861 - val_mae: 10.4915\n",
      "Epoch 54/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 154.2908 - mae: 9.4652 - val_loss: 172.7795 - val_mae: 10.1516\n",
      "Epoch 55/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 148.0592 - mae: 9.1970 - val_loss: 165.0517 - val_mae: 9.8246\n",
      "Epoch 56/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 142.3262 - mae: 8.9430 - val_loss: 157.4978 - val_mae: 9.4990\n",
      "Epoch 57/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 136.9268 - mae: 8.6967 - val_loss: 151.5731 - val_mae: 9.2459\n",
      "Epoch 58/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 132.6557 - mae: 8.5009 - val_loss: 145.1481 - val_mae: 8.9663\n",
      "Epoch 59/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 128.3124 - mae: 8.2920 - val_loss: 140.4225 - val_mae: 8.7604\n",
      "Epoch 60/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 125.0982 - mae: 8.1415 - val_loss: 137.0464 - val_mae: 8.6070\n",
      "Epoch 61/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 122.7963 - mae: 8.0252 - val_loss: 131.0942 - val_mae: 8.3394\n",
      "Epoch 62/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 119.3723 - mae: 7.8433 - val_loss: 127.8280 - val_mae: 8.1882\n",
      "Epoch 63/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 117.3271 - mae: 7.7395 - val_loss: 125.0833 - val_mae: 8.0599\n",
      "Epoch 64/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 115.5397 - mae: 7.6484 - val_loss: 122.0140 - val_mae: 7.9163\n",
      "Epoch 65/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 113.7690 - mae: 7.5528 - val_loss: 119.6217 - val_mae: 7.8053\n",
      "Epoch 66/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 112.2663 - mae: 7.4896 - val_loss: 116.0222 - val_mae: 7.6379\n",
      "Epoch 67/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 110.7426 - mae: 7.3962 - val_loss: 114.7991 - val_mae: 7.5826\n",
      "Epoch 68/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 109.7594 - mae: 7.3551 - val_loss: 112.5556 - val_mae: 7.4819\n",
      "Epoch 69/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 108.5909 - mae: 7.2942 - val_loss: 111.3862 - val_mae: 7.4303\n",
      "Epoch 70/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 107.7071 - mae: 7.2574 - val_loss: 110.7290 - val_mae: 7.3980\n",
      "Epoch 71/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 106.9969 - mae: 7.2283 - val_loss: 110.5714 - val_mae: 7.3861\n",
      "Epoch 72/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 106.1254 - mae: 7.1956 - val_loss: 108.5144 - val_mae: 7.2972\n",
      "Epoch 73/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 105.1834 - mae: 7.1514 - val_loss: 107.6122 - val_mae: 7.2584\n",
      "Epoch 74/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 104.4404 - mae: 7.1230 - val_loss: 107.2557 - val_mae: 7.2410\n",
      "Epoch 75/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 103.6568 - mae: 7.0942 - val_loss: 105.3707 - val_mae: 7.1590\n",
      "Epoch 76/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 102.7843 - mae: 7.0588 - val_loss: 105.0344 - val_mae: 7.1399\n",
      "Epoch 77/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 101.9486 - mae: 7.0267 - val_loss: 104.1693 - val_mae: 7.0968\n",
      "Epoch 78/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 100.9874 - mae: 6.9870 - val_loss: 103.8543 - val_mae: 7.0800\n",
      "Epoch 79/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 100.3924 - mae: 6.9625 - val_loss: 103.2371 - val_mae: 7.0500\n",
      "Epoch 80/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 99.7208 - mae: 6.9359 - val_loss: 103.0342 - val_mae: 7.0353\n",
      "Epoch 81/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 99.1003 - mae: 6.9124 - val_loss: 102.8856 - val_mae: 7.0240\n",
      "Epoch 82/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 98.5712 - mae: 6.8897 - val_loss: 100.4591 - val_mae: 6.9300\n",
      "Epoch 83/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 97.7532 - mae: 6.8665 - val_loss: 99.8447 - val_mae: 6.9033\n",
      "Epoch 84/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 97.1734 - mae: 6.8424 - val_loss: 99.7394 - val_mae: 6.8933\n",
      "Epoch 85/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 96.6997 - mae: 6.8255 - val_loss: 98.1902 - val_mae: 6.8347\n",
      "Epoch 86/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 96.0611 - mae: 6.8050 - val_loss: 98.3311 - val_mae: 6.8266\n",
      "Epoch 87/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 95.4701 - mae: 6.7765 - val_loss: 96.7837 - val_mae: 6.7805\n",
      "Epoch 88/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 94.8974 - mae: 6.7704 - val_loss: 97.1745 - val_mae: 6.7797\n",
      "Epoch 89/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 94.5071 - mae: 6.7435 - val_loss: 97.3909 - val_mae: 6.7761\n",
      "Epoch 90/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 94.0929 - mae: 6.7229 - val_loss: 96.2902 - val_mae: 6.7408\n",
      "Epoch 91/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 93.6635 - mae: 6.7154 - val_loss: 96.6888 - val_mae: 6.7423\n",
      "Epoch 92/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 93.3074 - mae: 6.6941 - val_loss: 96.3774 - val_mae: 6.7263\n",
      "Epoch 93/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 92.8687 - mae: 6.6759 - val_loss: 95.8198 - val_mae: 6.7044\n",
      "Epoch 94/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 92.4624 - mae: 6.6640 - val_loss: 95.9938 - val_mae: 6.7016\n",
      "Epoch 95/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 92.1518 - mae: 6.6430 - val_loss: 94.2399 - val_mae: 6.6496\n",
      "Epoch 96/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 91.5691 - mae: 6.6438 - val_loss: 94.4558 - val_mae: 6.6462\n",
      "Epoch 97/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 91.1784 - mae: 6.6209 - val_loss: 94.6255 - val_mae: 6.6425\n",
      "Epoch 98/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 90.9069 - mae: 6.6012 - val_loss: 92.8470 - val_mae: 6.5943\n",
      "Epoch 99/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 90.4293 - mae: 6.6090 - val_loss: 91.5302 - val_mae: 6.5707\n",
      "Epoch 100/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 90.2429 - mae: 6.6311 - val_loss: 91.6628 - val_mae: 6.5617\n",
      "Epoch 101/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.8189 - mae: 6.6074 - val_loss: 92.3942 - val_mae: 6.5697\n",
      "Epoch 102/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.6331 - mae: 6.5789 - val_loss: 91.3577 - val_mae: 6.5476\n",
      "Epoch 103/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.3690 - mae: 6.5871 - val_loss: 92.0462 - val_mae: 6.5520\n",
      "Epoch 104/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 89.1596 - mae: 6.5589 - val_loss: 91.6510 - val_mae: 6.5404\n",
      "Epoch 105/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 88.9601 - mae: 6.5602 - val_loss: 92.0108 - val_mae: 6.5409\n",
      "Epoch 106/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 88.8600 - mae: 6.5411 - val_loss: 92.2693 - val_mae: 6.5400\n",
      "Epoch 107/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 88.5332 - mae: 6.5188 - val_loss: 90.5649 - val_mae: 6.5027\n",
      "Epoch 108/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 88.1744 - mae: 6.5387 - val_loss: 90.6100 - val_mae: 6.4988\n",
      "Epoch 109/150\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 87.9646 - mae: 6.5290 - val_loss: 91.1675 - val_mae: 6.5023\n",
      "Epoch 110/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 87.8174 - mae: 6.5051 - val_loss: 91.7958 - val_mae: 6.5106\n",
      "Epoch 111/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 87.7339 - mae: 6.4839 - val_loss: 91.2251 - val_mae: 6.4966\n",
      "Epoch 112/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 87.4921 - mae: 6.4834 - val_loss: 89.3927 - val_mae: 6.4627\n",
      "Epoch 113/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 87.1328 - mae: 6.5172 - val_loss: 89.6778 - val_mae: 6.4623\n",
      "Epoch 114/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 87.0556 - mae: 6.5057 - val_loss: 90.4079 - val_mae: 6.4700\n",
      "Epoch 115/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.9680 - mae: 6.4731 - val_loss: 89.1897 - val_mae: 6.4476\n",
      "Epoch 116/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.6698 - mae: 6.4968 - val_loss: 88.4016 - val_mae: 6.4392\n",
      "Epoch 117/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 86.5364 - mae: 6.5191 - val_loss: 88.3249 - val_mae: 6.4338\n",
      "Epoch 118/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.3733 - mae: 6.5145 - val_loss: 88.8980 - val_mae: 6.4320\n",
      "Epoch 119/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.2772 - mae: 6.4853 - val_loss: 88.4043 - val_mae: 6.4206\n",
      "Epoch 120/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 86.0664 - mae: 6.4853 - val_loss: 89.0681 - val_mae: 6.4230\n",
      "Epoch 121/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 85.9114 - mae: 6.4591 - val_loss: 88.4025 - val_mae: 6.4117\n",
      "Epoch 122/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 85.7752 - mae: 6.4861 - val_loss: 88.4416 - val_mae: 6.4076\n",
      "Epoch 123/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 85.5945 - mae: 6.4567 - val_loss: 87.2236 - val_mae: 6.3978\n",
      "Epoch 124/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 85.4458 - mae: 6.4884 - val_loss: 86.6230 - val_mae: 6.3972\n",
      "Epoch 125/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 85.2989 - mae: 6.5113 - val_loss: 86.7855 - val_mae: 6.3882\n",
      "Epoch 126/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 85.1733 - mae: 6.5072 - val_loss: 86.1054 - val_mae: 6.3927\n",
      "Epoch 127/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 84.9961 - mae: 6.5228 - val_loss: 86.6971 - val_mae: 6.3800\n",
      "Epoch 128/150\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 84.8280 - mae: 6.4845 - val_loss: 87.5583 - val_mae: 6.3782\n",
      "Epoch 129/150\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 84.7917 - mae: 6.4384 - val_loss: 86.7529 - val_mae: 6.3717\n",
      "Epoch 130/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 84.6055 - mae: 6.4635 - val_loss: 85.7751 - val_mae: 6.3847\n",
      "Epoch 131/150\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 84.7247 - mae: 6.5253 - val_loss: 85.8555 - val_mae: 6.3798\n",
      "Epoch 132/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 84.5599 - mae: 6.5118 - val_loss: 86.0661 - val_mae: 6.3703\n",
      "Epoch 133/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 84.4489 - mae: 6.4838 - val_loss: 86.9829 - val_mae: 6.3618\n",
      "Epoch 134/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 84.3248 - mae: 6.4422 - val_loss: 87.4116 - val_mae: 6.3645\n",
      "Epoch 135/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 84.2841 - mae: 6.4250 - val_loss: 87.0681 - val_mae: 6.3595\n",
      "Epoch 136/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 84.1659 - mae: 6.4313 - val_loss: 86.9911 - val_mae: 6.3576\n",
      "Epoch 137/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 84.1356 - mae: 6.4298 - val_loss: 87.0659 - val_mae: 6.3569\n",
      "Epoch 138/150\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 84.0727 - mae: 6.4123 - val_loss: 86.2291 - val_mae: 6.3521\n",
      "Epoch 139/150\n",
      "6/6 [==============================] - ETA: 0s - loss: 73.0312 - mae: 6.28 - 0s 5ms/step - loss: 83.9638 - mae: 6.4533 - val_loss: 85.4325 - val_mae: 6.3578\n",
      "Epoch 140/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.8582 - mae: 6.4783 - val_loss: 86.5658 - val_mae: 6.3478\n",
      "Epoch 141/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 83.7107 - mae: 6.4201 - val_loss: 86.9459 - val_mae: 6.3470\n",
      "Epoch 142/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.6931 - mae: 6.4105 - val_loss: 86.2624 - val_mae: 6.3461\n",
      "Epoch 143/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 83.6537 - mae: 6.4363 - val_loss: 87.0847 - val_mae: 6.3470\n",
      "Epoch 144/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.6739 - mae: 6.4007 - val_loss: 85.9031 - val_mae: 6.3442\n",
      "Epoch 145/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.5505 - mae: 6.4426 - val_loss: 85.2660 - val_mae: 6.3500\n",
      "Epoch 146/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 83.5128 - mae: 6.4707 - val_loss: 85.1145 - val_mae: 6.3518\n",
      "Epoch 147/150\n",
      "6/6 [==============================] - ETA: 0s - loss: 82.8903 - mae: 6.20 - 0s 4ms/step - loss: 83.6697 - mae: 6.4872 - val_loss: 86.2563 - val_mae: 6.3387\n",
      "Epoch 148/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.4053 - mae: 6.4185 - val_loss: 86.6985 - val_mae: 6.3376\n",
      "Epoch 149/150\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 83.4474 - mae: 6.4086 - val_loss: 87.3046 - val_mae: 6.3402\n",
      "Epoch 150/150\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 83.4663 - mae: 6.3844 - val_loss: 87.9810 - val_mae: 6.3494\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', min_delta = 0.001, patience = 10, verbose = 1, mode = 'auto')\n",
    "callbacks = [es]\n",
    "historico = model.fit(x_train, \n",
    "                             y_train, \n",
    "                             epochs = 150, \n",
    "                             batch_size=64,\n",
    "                             verbose = 1,\n",
    "                             validation_split = 0.2 ,\n",
    "                             shuffle=True,\n",
    "                             callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.expand_dims(x_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_simples = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.251049916884478"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(y_test, np.mean(pred_simples,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2</td>\n",
       "      <td>21.015167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.8</td>\n",
       "      <td>21.172346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>21.469160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>21.902241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.2</td>\n",
       "      <td>21.707869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.9</td>\n",
       "      <td>21.073530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24.1</td>\n",
       "      <td>22.059984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>50.0</td>\n",
       "      <td>21.910994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>26.7</td>\n",
       "      <td>21.599499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>25.0</td>\n",
       "      <td>21.603239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test     y_pred\n",
       "0       7.2  21.015167\n",
       "1      18.8  21.172346\n",
       "2      19.0  21.469160\n",
       "3      27.0  21.902241\n",
       "4      22.2  21.707869\n",
       "..      ...        ...\n",
       "97     21.9  21.073530\n",
       "98     24.1  22.059984\n",
       "99     50.0  21.910994\n",
       "100    26.7  21.599499\n",
       "101    25.0  21.603239\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resultado = pd.DataFrame()\n",
    "resultado['y_test'] = y_test\n",
    "resultado['y_pred'] = np.mean(pred_simples,axis=1)\n",
    "\n",
    "resultado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valor_venal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
